\documentclass[a4paper,12pt]{article}
\usepackage{amsmath, amssymb}
\usepackage{xcolor}
\usepackage{ulem}        % underline
\usepackage{tcolorbox}   % colored boxes (if needed)
\usepackage{pifont}
\usepackage{xcolor}
\usepackage{tikz}
\usetikzlibrary{trees} % for tree structures

\begin{document}
\tableofcontents 
\newpage
\begin{center}
\textbf{Math√©matiques : CM}
\end{center}



\section{Bases of a Vector Space}

\subsection*{Definition 1}
Let $E$ be a vector space over a field $K$, let $n \in \mathbb{N}$, and let $\{x_1, x_2, \ldots, x_n\}$ be a family of vectors in $E$.  
We say that the family $\{x_1, x_2, \ldots, x_n\}$ is a \textbf{basis} of $E$ if it is both \textbf{linearly independent} and \textbf{spanning} (generating) for $E$.

\subsection*{Theorem 1 (Characterization of a Basis)}
Let $E$ be a vector space over $K$, let $n \in \mathbb{N}$, and let $\{x_1, x_2, \ldots, x_n\}$ be a family of vectors in $E$.  
Then $B = \{x_1, x_2, \ldots, x_n\}$ is a basis of $E$ if and only if:
\[
\forall x \in E, \ \exists! (\lambda_1, \lambda_2, \ldots, \lambda_n) \in K^n \text{ such that } 
x = \sum_{i=1}^{n} \lambda_i x_i.
\]
The scalars $\lambda_i$, $i \in \{1, 2, \ldots, n\}$ are called the \textbf{coordinates} of the vector $x$ in the basis $B$.

\section{Existence of a Basis}

\subsection*{Theorem 2}
Every non-zero vector space $E$ over a field $K$ admits at least one basis.

\subsection*{Theorem 3 (Incomplete Basis Theorem)}
Let $E$ be a vector space over $K$ that admits a finite generating family. Then:
\begin{enumerate}
    \item From every generating family of $E$, one can extract a basis of $E$.
    \item Every linearly independent family of $E$ can be extended to a basis of $E$.
\end{enumerate}

\subsection*{Definition 2}
In $\mathbb{R}^n$, the family $(e_1, \ldots, e_n)$ where for every $i \in \{1, \ldots, n\}$,
\[
e_i = (0, \ldots, 0, \underbrace{1}_{\text{$i$-th coordinate}}, 0, \ldots, 0)
\]
is a basis. It is called the \textbf{canonical basis} of $\mathbb{R}^n$.

\subsection*{Definition 3}
In $\mathbb{R}_n[X]$, the family $(1, X, \ldots, X^n)$ is a basis.  
It is called the \textbf{canonical basis} of $\mathbb{R}_n[X]$.

\section{Dimension of a Vector Space}

\subsection*{Definition 1}
Let $E$ be a vector space over a field $K$.  
We say that $E$ is of \textbf{finite dimension} if $E$ admits a finite generating family.

\subsection*{Theorem 1}
Let $E \neq \{0_E\}$ be a finite-dimensional vector space over $K$. Then:
\begin{enumerate}
    \item $E$ admits at least one basis.
    \item All bases of $E$ have the same cardinality.
\end{enumerate}

\subsection*{Definition 2}
Let $E$ be a finite-dimensional vector space over $K$.
\begin{enumerate}
    \item If $E \neq \{0_E\}$, we call the \textbf{dimension} of $E$, denoted $\dim(E)$, the cardinality of any basis of $E$.
    \item If $E = \{0_E\}$, we define $\dim(E) = 0$.
\end{enumerate}

\bigskip
\noindent \textbf{Examples:}  
$\dim(\mathbb{R}^n) = n$ and $\dim(\mathbb{R}_n[X]) = n + 1$.

\subsection*{Proposition}
Let E a $\mathbb{K}$ vector space such that dim(E) = n, n$\in \mathbb{N*}$ and B a family of p vectors, $p \in \mathbb{N*}$.
\bigskip

Then : 
\begin{enumerate}
    \item B is linearly independant $\implies p \leq n$
    \item B is a spanning family of E $\implies p \geq n$
    \item B is a basis of E $\implies (p \leq n) \land (p \geq n) \Leftrightarrow p = n$
    \item (p = n) $\implies (B \text{ is linearly independant})$
\end{enumerate}
\bigskip
\noindent \textbf{Examples:}  
We have $\{1, X - 1, (X + 1)^2 \}$ = $\mathbb{R}_2[X]$ and $dim(\mathbb{R}_2[X]) = 3$

\bigskip
Then : \begin{enumerate}
    \item $Card(\{1, X - 1, (X + 1)^2 \}) = 3 = dim(\mathbb{R}_2[X])$
    \item B is linearly independant
\end{enumerate}

Proof that B is linearly independant : 
\[
\begin{pmatrix}
1 & -1 & 1 \\
0 & 1 & 2 \\
0 & 0 & 1
\end{pmatrix}
:
\begin{pmatrix}
    0 \\
    0 \\
    0
\end{pmatrix}
\implies a = b = c = 0 \implies a \,+ \, b \, \times \, (X - 1) + c \,\times\,(X+1)^2 = 0_{\mathbb{R}_2[X]}
\]

\bigskip
\noindent \textbf{Examples:} \\

$F = span(u_1 =, u_2, u_3), \forall i \in [\, | 1, 3 | \,], \forall \, u_i \text{ from } \mathbb{R^3}$
\bigskip

Find values of t such that $dim(F) = 3$, where :

\[
u_1 = (0, t^2, 1)
\]
\[
u_2 = (0, 0, 3)
\]
\[
u_3 = (1, 1, 3)
\]

$dim(F) = 3 \Leftrightarrow F = E $ because F is a linear subspace of E.
\bigskip

We are looking for a value of B such that $span(B) = \mathbb{R}^3 \implies$ we are looking for t such that B is a basis of $\mathbb{R}^3$
since $Card(B) = 3 = dim(E) \implies$ we are looking for t such that B is linearly independant.

\[\Leftrightarrow
\begin{pmatrix}
    0 & 0 & 1 \\
    t^2 & 0 & 1 \\
    1 & 3 & 3 
\end{pmatrix}
:
\begin{pmatrix}
    0 \\
    0 \\
    0
\end{pmatrix}
\Leftrightarrow
\begin{pmatrix}
    1 & 3 & 3 \\
    t^2 & 0 & 1 \\
    0 & 0 & 1 
\end{pmatrix}
:
\begin{pmatrix}
    0 \\
    0 \\
    0
\end{pmatrix}
\Leftrightarrow
\begin{pmatrix}
    1 & 3 & 3 \\
    0 & -3t^2 & 1 -3t^2 \\
    0 & 0 & 1 
\end{pmatrix}
:
\begin{pmatrix}
    0 \\
    0 \\
    0
\end{pmatrix}
\]

Case t = 0 :

$(a_1, a_2, a_3) \neq (0, 0, 0)$

\bigskip
Case t $\neq$ 1 :

Kramer system : $a_1 = a_2 = a_3 = 0$

\section{Linear Maps}

\subsection*{Definition :}
Let A,B two $\mathbb{K}$ vector space and 
\[
f : \begin{cases}
    A \to B \\
    \alpha \mapsto f(x)
\end{cases}
\]

$\alpha$ map from A to B. Then :

\[
f \text{ is linear} \Leftrightarrow \begin{cases}
    \forall (\alpha, u) \in \mathbb{K} \times A, f(\alpha u) = \alpha f(u) \\
    \forall (u, v) \in A^2, f(u + v) = f(u) + f(v)
\end{cases}
\]
\[
\Leftrightarrow \forall (\alpha, u, v) \in \mathbb{K} \times A^2, f(\alpha u + v) = \alpha f(u) + f(v)
\]

Notation : f is a linear map from A to B $\Leftrightarrow f \in \mathcal{L}(A,B)$ \\

\textbf{Remark (necessary condition) :} $f \in \mathcal{L}(A,B)\implies f(0_A) = O_B$ \\

\textbf{Contrapositive :} $f(0_A) \neq O_B \implies f \notin \mathcal{L}(A,B)$

\subsection*{Definition :}

Let $f \in \mathcal{L}(A,B)$ with A and B two $\mathbb{K}$ vector space. Then :

\begin{itemize}
    \item We call $Ker(f) = \{ X \in A, f(X) = 0_B\} \subset A$
    \item We call $Im(f) = \{Y \in B, f(X) = Y \} = \{f(X), X \in A\} \subset B$
\end{itemize}

\subsection*{Proposition :}

\begin{enumerate}
    \item $Ker(f)$ is a linear subspace of A
    \item $Im(f)$ is a linear subspace of B
\end{enumerate}

\subsection*{Definition :}

Let $f \in \mathcal{L}(A,B)$.
\[
\begin{cases}
    f \text{ is injective} \Leftrightarrow Ker(f) = \{0_A\} \\
    f \text{ is surjective} \Leftrightarrow Im(f) = B
\end{cases}
\]

\subsection*{Proof :}

\[f \text{ is surjective} \implies \forall \, Y \in B, \exists \, x \in A, f(X) = Y\]
\[\implies B \subset Im(f) \land Im(f) \subset B \text{ by definition} \implies Im(f) = B\]

\section{Determinant}

\subsection{Determinant of order 2}

A determinant of order 2 is the determinant of a matrix from $\mathbb{M}_2\mathbb{(R)}$ \\

Let $A \in \mathbb{M}_2\mathbb{(R)}, $

\[ A = \begin{pmatrix}
    a_{11} & a_{12} \\
    a_{21} & a_{22}
\end{pmatrix}
\] \\

We call determinant of A and denote $det(A)$ the real number :
\[det(A) = a_{11} \times a_{22} - a_{21} \times a_{12}\]

\subsection{Determinant of order 3}

A determinant of order 3 is the determinant of a matrix from $\mathbb{M}_3\mathbb{(R)}$ \\

Let $A \in \mathbb{M}_3\mathbb{(R)}, $

\[ A = \begin{pmatrix}
    a_{11} & a_{12} & a_{13} \\
    a_{21} & a_{22} & a_{23} \\
    a_{31} & a_{32} & a_{33}
\end{pmatrix}
\] \\

We call determinant of A and denote $det(A)$ the real number :
\[det(A) = a_{11} \times 
    \begin{vmatrix}
        a_{22} & a_{23} \\
        a_{32} & a_{33}
    \end{vmatrix}
     - a_{12} \times
     \begin{vmatrix}
        a_{21} & a_{23} \\
        a_{31} & a_{33}
    \end{vmatrix}
      - a_{13} \times 
      \begin{vmatrix}
        a_{21} & a_{22} \\
        a_{31} & a_{32}
    \end{vmatrix}
\]

\newpage 
\subsection{General determinant for $A \in \mathbb{M}_n\mathbb{(R)}$}

Let $A = (a_{ij})_{ \, 1 \leq i \leq n \,  \land \, 1 \leq j \leq n }$. We can minor of indices (i, j) the determinant $\Delta_{ij}$ of the $(n-1) \times (n-1)\text{matrix}$ resulting from remaining row i and column j from A. \\

Then : 
\[ det(A) = \sum_{i = 1}^{n}{(-1)^{i + j} \times \Delta_{ij} \times a_{ij} } \text{if we can expand it with respect to column j}
\]
\[ det(A) = \sum_{j = 1}^{n}{(-1)^{i + j} \times \Delta_{ij} \times a_{ij}} \text{if we can expand it with respect to row i}\]

\subsection*{Example :}

\[ A = \begin{pmatrix}
    1 & 2 & 0 \\
    4 & 5 & 6 \\
    6 & 5 & 4
\end{pmatrix} \]

\[
det(A) = (-1)^{1+1} \times 1 \times \begin{vmatrix}
    5 & 6 \\
    5 & 4
\end{vmatrix} + (-1)^{1+2} \times 2 \times \begin{vmatrix}
    4 & 6 \\
    6 & 4
\end{vmatrix} (-1)^{1+3} \times 0 \times \begin{vmatrix}
    4 & 5 \\
    6 & 5
\end{vmatrix}
\]
\[\implies det(A) = -10 -2\times (-20) = 30\]

\subsection{Properties}
\begin{enumerate}
    \item Let $(A, B) \in \mathbb{M}_n^2\mathbb{(R)}, A = (a_{ij})_{ \, 1 \leq i \leq n \,  \land \, 1 \leq j \leq n }, B = (b_{ij})_{ \, 1 \leq i \leq n \,  \land \, 1 \leq j \leq n }$

    \[
    det(\lambda A) = \lambda^n det(A)
    \]

    \[
    det(AB) = det(A) \times det(B)
    \]
    
    \item \[det(A^T) = det(A)\]
    \item When doing a row echelon for instance $\alpha R_1 + \beta R_2$: \[ det(A) = \alpha \times \beta \times det(C)\] where C is the matrix that has been row echelon
\end{enumerate}

\subsection{Determinant and invertibility}

Let $A \in \mathbb{M}_n\mathbb{(R)}$ :

\[
A \;\text{invertible} \Leftrightarrow \exists \, B \in \mathbb{M}_n\mathbb{(R)} \; AB = BA = I_n. \; B \text{ is denoted } A^{-1}.
\]

\[
\implies | A \times A^{-1} |= | I_n | \implies | A | | A^{-1} | = | I_n |
\]
\[ \implies det(A) \neq 0 \land det(A^{-1}) = \frac{1}{det(A)}\]
\[
D : \begin{cases}
    \mathbb{M}_n\mathbb{(R)} \to \mathbb{R} \\
    A \mapsto det(A)
\end{cases}
\]

\[\text{where D is the mapping of the function of the determinant.}\]

\subsection{Determinant of some special matrices}

Let $A \in \mathbb{M}_n\mathbb{(R)}$

\begin{itemize}
    \item A is diagonal $\Leftrightarrow (i \neq j \implies a_{ij} = 0)$
    \[
        \textcolor{red}{det(A) = \prod_{i = 1}^{n}{a_{ii}}}
    \]
    \item A is a upper-triangle matrix $\Leftrightarrow j < i \implies a_{ij} = 0$
    \[
        det(A) = \prod_{i = 1}^{n}{a_{ij}}
    \]
    \item A is a lower-triangle matrix $\Leftrightarrow j > i \implies a_{ij} = 0$
    \[
        det(A) = \prod_{i = 1}^{n}{a_{ij}}
    \]
\end{itemize}

\subsection*{Example}
\bigskip
$A = \begin{pmatrix}
    9 & -4  & 2 \\
    21 & 8 & 3 \\
    25 & 0 & 5
    \end{pmatrix}
$\\

\[det(A) = \begin{vmatrix}
    -1 & -4 & 2 \\
    6 & 8 & 3 \\
    0 & 0 & 5
\end{vmatrix} (C1 - 5C3) = \begin{vmatrix}
    -1 & -4 & 2 \\
    0 & -16 & 15 \\
    0 & 0 & 5
\end{vmatrix} (R2 + 6 R1) = 5\times 16 = 80\]

Or

\[
det(A) = (-1)^{3+1} \times 25 \begin{vmatrix}
    -4 & 2 \\
    8 & 5
\end{vmatrix} + (-1)^{3+3} \times 5 \begin{vmatrix}
    9 & -4 \\
    21 & 8
\end{vmatrix} = 80
\]

\subsection*{Example}

Find values of X such that A - XI is not invertible, $X \in \mathbb{R}$

\[
A = \begin{pmatrix}
    1 & 0 & 2 \\
    2 & 1 & 0 \\
    1 & 3 & 2
\end{pmatrix} \implies A - XI = \begin{pmatrix}
    1 - X & 0 & 2 \\
    2 & 1 - X & 0 \\
    1 & 3 & 2 - X
\end{pmatrix}
\]

\[ \begin{vmatrix}
    A - XI
\end{vmatrix} = \begin{vmatrix}
    1 - X & 0 & 2 \\
    2 & 1 - X & 0 \\
    4 - X & 4 - X & 4 - X
\end{vmatrix} (R1 + R2 + R3) = (4 - X)\begin{vmatrix}
    1 - X & 0 & 2 \\
    2 & 1 - X & 0 \\
    1 & 1 & 1
\end{vmatrix}\]

\[
    = \begin{vmatrix}
        1 - X & X - 1 & 1 + X \\
        2 & -1 - X & -2 \\
        1 & 0 & 0
    \end{vmatrix} = (4 - X) ((-2)(X - 1) + (1 + X)^2) = (4 - X) (X^2 +3)
\]

\[
\mathbb{S} = \{4\} \]

\section{Diagonalisation of endomorphism}

Let $f \in \mathcal{L}(E)$ with $E$ a $\mathbb{K}$ vector space of finite dimension :

\[Mat_{BB}(t) = A\]
\[A \in \mathbb{M}_n(\mathbb{R})\]

\subsection{Definition : Eigen Value}

Let $A \in \mathbb{M}_n(\mathbb{K})$ and $\lambda \in \mathbb{K}$, we call eigen value of A any scalar $\lambda \in \mathbb{K}$ such that $\exists \, U \in \mathbb{K}^n, A \vec{U} = \lambda \vec{U}$ 
Then we call $U$ the eigen value associated with $\lambda$. Notation : for a given matrix $A \in \mathbb{M}_n(\mathbb{K})$, $spectrum(A)$ is how we denote the set of eigen values of A.

\subsection{Example}
\[ \begin{pmatrix}
    1 & 2 \\
    3 & 4 \\
\end{pmatrix}
\begin{pmatrix}
    x\\
    y
\end{pmatrix}, \lambda\in \mathbb{R} \text{ and } A = Mat_B(t), t \in \mathcal{L}(E),  E = \mathbb{K} \text{ vector space, } dim(E) = 2\]

\[\text{We look for} \begin{pmatrix}
    x \\
    y
\end{pmatrix}_B \mapsto \begin{pmatrix}
    x + 2y \\
    3x + 4y
\end{pmatrix}\]

\subsection{Definition : Eigen Space}

Let $A \in \mathbb{M}_n\mathbb{K} \text{ and } \lambda \in spectrum(A).$ Then we call eigen space associated with $\lambda$ : $E_\lambda = \{\vec{U}\in \mathbb{K}^n, A\vec{U} = \lambda\vec{U}\} \subset \mathbb{K}^n$ 

\subsubsection{Proof}

Let $E_y$ a linear subspace of E :
\begin{itemize}
    \item $(A) \times \vec{0} = \vec{0} \implies \vec{0} \in E_\lambda \implies E_y \neq \emptyset$
    \item $\forall (\alpha, \vec{U}, \vec{V}) \in \mathbb{K} \times E_\lambda^2, A(\alpha\vec{U} + \vec{V}) = A(\alpha\vec{U}) + A(\vec{V}) = \lambda\alpha\vec{U} + \lambda\vec{V} = \lambda(\alpha\vec{U} + \vec{V}) \implies \alpha\vec{U} + \vec{V} \in \mathbb{E}_\lambda$
    \item Thus, $E_y$ is not empty and is closed by linear combination $\implies E_y$ is a linear subspace of $E$ 
\end{itemize}
% ----------------------
% TO DO
% -----------------------

\subsection*{Defintion 2 : Eigen Space}

Let E a $\mathbb{K}$ vector space of eigen vectors and $A \in \mathbb{M}_n(\mathbb{R})$ the matrix of an endomorphism of E; $\lambda$ an eigen value of A. The we call eigen space associated with $\lambda$ :

\[ E_\lambda = Ker(A - \lambda I)\]

\section{Diagonalisability}

\subsection{Characteristic polynomial}

\subsubsection{Definition}
Let $A \in \mathbb{M}_n(\mathbb{K})$. We call characteristic polynomial and denote $P_A(X)$ the following polynomial :

\[P_A(X) = det(A- XI)\]

\subsubsection{Proposition}

Let $A \in \mathbb{M}_n(\mathbb{K})$. We call $spectrum(A)$ the following set : 

\[spectrum(A) = \{\lambda \in k, P_A(\lambda) = 0\}\]

\subsubsection*{Example}

Let $A \in \mathbb{M}_n(\mathbb{K})$, such that :
\[A = \begin{pmatrix}
    0 & 1 & 1 \\
    -1 & 2 & 1 \\
    0 & 0 & 1
\end{pmatrix}\]

\[
P_A(X) = \begin{vmatrix}
    -X & 1 & 1 \\
    -1 & 2-X & 1 \\
    0 & 0 & 1 - X
\end{vmatrix}
\]

\[ = (-1)^{3+3} \times (1-X) \times \begin{vmatrix}
    -X & 1 \\
    -1 & 2 -X
\end{vmatrix}
\]

\[
= (1 - X)(-2X + X^2 + 1) = (1 - X) (X-1)^2 = (1-X)^3
\]

\subsubsection{Defintion}

Let $f \in \mathcal{L}(E)$ and $A = Mat(f)$ in the standard basis. We say A is diagonalisable if there exists an eigen basis of f in E, i.e a basis $B_e = (u_1, ..., u_n)$ such that $\forall i \in [|1, n|], f(u_i) = \lambda_i U_i, \lambda_i \in \mathbb{K}$

\subsubsection{Definition 2}

Let $f \in \mathcal{L}(E)$ and $A = Mat(f)$ in the standard basis. A is diagonalisable if $\exists P \in M_n(\mathbb{R})$, \textbf{invertible} such that :

\[P^{-1}AP = D \text{, when D is diagonal}\]

\subsubsection{Theorem}

Let $f \in \mathcal{L}(E)$ and $A = Mat_B(f)$.

Then the following proposition are equivalent :
\begin{itemize}
    \item A is diagonalisable
    \item There exists an eigen basis for $f$ in $E$
    \item $\sum_{ \lambda \in spectrum(A)}{dim(E_\lambda)} = dim(E)$
    \item $\sum_{ \lambda \in spectrum(A)}{E_\lambda}= E_{\lambda_1} + E_{\lambda_2} + ... + E_{\lambda_n}= E$
\end{itemize}

\subsubsection{Example}

Let : 
\[A = \begin{pmatrix}
    3 & -1 & 1 \\
    0 & 2 & 0 \\
    1 & -1 & 3
\end{pmatrix} \implies P_A(X) \begin{vmatrix}
    3 - X & -1 & 1 \\
    0 & 2 - X & 0 \\
    1 & -1 & 3 - X
\end{vmatrix}\]

\[= (-1)^(2+2) \times (2-X) \times ((3-X)^2 - 1) = ((2 - X) (3 - X - 1)(3 - X + 1))\]
\[= (2-X)^2(4-X) \implies spectrum(A) = \{2, 4\}\]\\

Thus : $E_2 = \{x \in E, AX = 2X\} = Ker(A - 2I)$
\[\implies \begin{pmatrix}
    1 & -1 & 1 \\
    0 & 0 & 0 \\
    1 & -1 & 1
\end{pmatrix}:\begin{pmatrix}
    0 \\
    0 \\
    0
\end{pmatrix} \Leftrightarrow x - y + z = 0 \implies \{ \begin{pmatrix}
y-z \\
0 \\
z
\end{pmatrix}_B , (y,z) \in \mathbb{R}^2 \}\]

\[ = span(\begin{pmatrix}
    1\\
    1 \\ 
    0
\end{pmatrix}_B , \begin{pmatrix}
    -1 \\
    0 \\ 
    1
\end{pmatrix}_B) \implies dim(E_2) = 2\]
\bigskip

Also : $E_4 = (Ker(A - 4I)) = Ker\begin{pmatrix}
-1 & -1 & 1\\
0 & -2 & 0 \\
1 & -1 & -1 \\
\end{pmatrix}$
\[\begin{pmatrix}
1 & 1 & -1\\
0 & -2 & 0 \\
1 & -1 & -1 \\
\end{pmatrix} : \begin{pmatrix}
    0 \\
    0 \\
    0
\end{pmatrix} \Leftrightarrow 
\begin{pmatrix}
1 & 1 & -1\\
0 & -2 & 0 \\
0 & -2 & 0 \\
\end{pmatrix} : \begin{pmatrix}
    0 \\
    0 \\
    0
\end{pmatrix} \]

\[\begin{pmatrix}
1 & 1 & -1\\
0 & -2 & 0 \\
0 & 0 & 0 \\
\end{pmatrix} : \begin{pmatrix}
    0 \\
    0 \\
    0
\end{pmatrix} \implies \begin{cases}
    x = z \\
    y = 0 \\
    z \in \mathbb{R}
\end{cases} \implies E_4 = span(\begin{pmatrix}
    1 \\
    0\\ 
    1
\end{pmatrix})\]

\[\implies dim(E_1) = 1 \implies dim(E_1) + dim(E_2) = 1 + 2 = 3 = dim(E) \implies A \text{ is diagonalisable.}\]
\end{document}