\documentclass[a4paper,12pt]{article}
\usepackage{amsmath, amssymb}
\usepackage{xcolor}
\usepackage{ulem}        % underline
\usepackage{tcolorbox}   % colored boxes (if needed)
\usepackage{pifont}
\usepackage{xcolor}
\usepackage{tikz}
\usetikzlibrary{trees} % for tree structures


\begin{document}

\begin{center}
\textbf{Math√©matiques : CM}
\end{center}

\[
(\Omega, P(\Omega), \mathbb{P}) \Leftrightarrow \\
\]

\bigskip
\begin{center}
\text{A random variable \( X \) is defined by:}
\[
X : \Omega \rightarrow \mathbb{R}
\quad \text{such that} \quad
\Omega \mapsto X(\Omega)
\]
\bigskip

\text{The generative function is defined by :}
\[
P : \mathbb{R} \rightarrow \mathbb{R}
\quad t \mapsto a_0*t^0 + a_1 * t^1 + a_2 * t^2 +...+a_n * t^n
\]
\[
\text{\{(X = k), k } \in X(\Omega) \text{ \} = partition of }\Omega
\]

\end{center}


\begin{center}
\Large \textcolor{red}{\section*{Generating Function}}
\end{center}
\textcolor{red}{\subsection*{Definition :}} 
\[
\text{Let X a random variable such that } X(\Omega) = \left[\,|0, n|\,\right]
, n \in \mathbb{N}^*.
\]
\[
\text{ we call generating function of X the following polynomial :}
\]
\[
  G_X : \begin{cases}
    \mathbb{R} \rightarrow \mathbb{R}\\
 G \mapsto \sum_{ \, k \, \in \, X(\Omega)}{P(X = k) * t^k}
\end{cases}
\]

\textcolor{red}{Remarks :}\\

 \[\alpha(\Omega) \text{ can be different we can have : X}(\Omega) \subset \left[\,|\alpha, n|\,\right] \]
\bigskip

\textcolor{red}{\subsection*{Bernouilli :}}

\[
X \sim B(P) \Leftrightarrow
\begin{cases}
X (\Omega) = \{0,1\}\\
P(X= 0) = (1-p), P(X= 1) = p \\
\end{cases}
\]
\[
\Leftrightarrow G_X \begin{cases}
\mathbb{R} \rightarrow \mathbb{R}\\
t \mapsto (1-p) + pt
\end{cases}
\]

\textcolor{red}{\subsubsection*{Expected value and variance :}}\bigskip

\textcolor{red}{Theorem :} \bigskip

\text{Let X a random variable and $G_X$ its generative function :} \\

\textcolor{red}{\[
\begin{cases}
    G_X(1) = 1 \\
    \mathbb{E}(X) = G_X'(1)\\
    \mathbb{V}(X) = G_X''(1) + G_X'(1) - (G_X'(1))^2
\end{cases}
\]}
\bigskip
\textcolor{red}{\subsubsection*{Proof :}}\bigskip

\textcolor{red}{By definition :} \\
\[
  G_X : \begin{cases}
    \mathbb{R} \rightarrow \mathbb{R}\\
 t \mapsto \sum_{ \,k \, = \,0}^{n}{P(X = k) * t^k}
\end{cases}
\]\\
\[
\Rightarrow G_X(1) = \sum_{\,k \,= \,0}^{n}{P(X = k) = 1} \text{  because } \{(X = k), k\in  \left[\,|0, n|\,\right]\} \text{ is a partition of } \Omega
\]
\[
\Rightarrow G_X : \begin{cases}
    \mathbb{R} \rightarrow \mathbb{R} \\
    t \mapsto \sum_{\,k\,=\,1}^{n}{k \times P(X = k) \times t^{k}} 
\end{cases} 
\]\\
\[
\Rightarrow G_X' : \begin{cases}
    \mathbb{R} \rightarrow \mathbb{R} \\
    t \mapsto \sum_{\,k\,=\, 1}^{n}{k \times P(X  = k) \times t^{k-1}} \Rightarrow G_X' = \sum_{\,k\,=\, 1}^{n}
     = \sum_{\,k\,=\, 0}^{n}{k \times P(X  = k)} = \mathbb{E}(X)
\end{cases}
\]\\
\[
\mathbb{V}(X) = \mathbb{E}(X)-(\mathbb{E}(X))^2 = \mathbb{E}(X^2) - E(X)^2
\]
\bigskip
\textcolor{red}{\subsubsection*{Koenig-Huygens Theorem :}}\bigskip

\textcolor{red}{\[
\mathbb{V}(X) = \mathbb{E} ((X - \mathbb{E}(X))^2) \\
\]\\
\[
\mathbb{V}(X) = \mathbb{E}(X^2) - \mathbb{E}^2(X))\\
\]}

\[
G_X(t) = \sum_{\,k\, =\, 0}^{n}{P(X = k) \times t^k}
\]\\
\[
G_X'(t) = \sum_{\,k\, =\, 1}^{n}{k \times P(X = k) \times t^{k-1}}
\]\\
\[
G_X''(t) = \sum_{\,k\, =\, 2}^{n}{k(k-1) \times P(X = k) \times t^{k-2}}
\] \\
\text{We have : } \\\[ k(k-1)P(X = k) \times t^{k - 2} =
k^2 \times P(X = k) \times t^{k - 2} - k * P(X = k) \times t^{k-2} 
\]\\
\[
\Rightarrow \sum_{\,k\, =\, 2}^{n}{k^2 \times P(X = k) \times t^{k-2}} - \sum_{\,k\, =\, 2}^{n}{k \times P(X = k) \times t^{k-2}} = G_X''(t)
\]
\\
\[
\Rightarrow G_X''(1)= \sum_{\,k\, =\, 0}^{n}{k^2 \times P(X = k) } - \sum_{\,k\, =\, 0}^{n}{k \times P(X = k) }
\]\\
\[
\Rightarrow G_X''(1) = \mathbb{E}(X^2) - E(X) \text{ (1) }
\] \\
\text{(1)} \[
\Rightarrow G_X''(1) + G_X'(1) = \mathbb{E}(X^2)
\] 
\\
\[
\Rightarrow G_X''(1) + G_x'(1) - (G_x'(1))^2 = \mathbb{E}(X^2) - \mathbb{E}(X)
\]
\\
\[
\Rightarrow G_X''(1) + G_x'(1) - (G_x'(1))^2 = \mathbb{V} (X)
\]

\textcolor{red}{\subsection*{X + Y :}} \bigskip
\textcolor{red}{Let X and Y two finite random variable then :}\\
\textcolor{red}{\[
G_{X+Y} : \begin{cases}
\mathbb{R} \rightarrow \mathbb{R} \\
t \mapsto G_X(t) \times G_Y(t)
\end{cases}
\]\\
\[
\Leftrightarrow G_{X+Y} = G_X \times G_Y
\]}

\text{Ex :}\\
\[
Y \sim B(n, p) \Leftrightarrow \begin{cases}
    Y(\Omega) =  \left[\,|0, n|\,\right] \\
    \forall \, k\in Y(\Omega), P(Y = k) = \binom{n}{k} \times p^k \times q^{n-k}
 \end{cases}
\]
\[
\Leftrightarrow Y = \sum_{\,i\, =\,1}^{n}{X_i}
\]
\[
G_Y = \prod_{\,i\,=\,1}^{n} {G_{X_i} :  t \mapsto(q + pt)^n = \sum_{k = 0}^{n} {\binom{n}{k} \times q^{n-k}\times (pt)^k}}
\]
\[
\sum_{\,k \,=\, 0}^{n} {\binom{n}{k} \times q^{n-k}\times p^k \times t^k}
\]\\
\[
\Rightarrow \mathbb{P}(Y = t) \Leftrightarrow G_{X+Y} = G_X \times G_Y
\]\\

\newpage

\subsection*{Power Series :}

\subsubsection*{Definition :}
\bigskip
\text{Let $\sum{u_n(x)}$ a series such that the general form $u_n(x)$ is of the following form :} 

\[
\forall n \in \mathbb{N}, u_n(x) = a_nx^n \text{ with} (a_n)_{n\,\in\,\mathbb{N}} \in \mathbb{R^N}\text{. } a_n \text{ should not depend on x.}
\]
\\
\text{Ex :} 
\[\sum{n^2x^n} \;, \; \sum{\frac{x^n}{n!} = e^x}\]

\textbf{Remark :} \\

\text{Power series are series of functions. In case of convergence at $x \in I \subset \mathbb{R}$,} \\

\text{we can define a function by the sum of the series. $\forall x \in I, f(x)= S(x) = \sum{P_n(x)}$} 

\bigskip
\bigskip

\text{$\forall (a_n) \in \mathbb{R^N}$, at x = 0, we have : $n = 0 \implies a_0 \times 0^0 = a_1n_1 \implies a_1 \times 0^1 = 0$}
\[\implies \sum{a_nx^n} \text{ is convergent at x = 0 and } f(0) = \sum{a_nx^n} = a_0\]

\bigskip

\subsection*{Convergence Radius :}
\bigskip
\subsubsection*{Definition :}

\text{Let $(a_n) \in \mathbb{R^N}$, and $\sum{a_nx^n}$ the power series associated with $a_n$ : $\sum{a_nx^n}$}
\bigskip
\[
  \text{we call R the radius of convergence of the series.}
  \text{Then } \exists \, R \in \mathbb{R_+} \cup \{+\infty\} \text{ such that:}
\]
\[
\begin{cases}
  \forall \, x \in \mathbb{R}, |x| < R \text{, the series converges absolutely.}\\
  \forall \, x \in \mathbb{R}, |x| > R \text{, } \sum{a_nx^n} \text{ diverges.}
\end{cases}
\]

\subsubsection*{Definition :} 
\bigskip
\text{We call open disc of convergence of $\sum{a_nx^n}$ an open interval $(-R, R)$ .} \\

\newpage
\textbf{Remark :}
\bigskip

This open disc of convergence is the included domain of function f :
\[f : \begin{cases}
  (-R, R) \rightarrow \mathbb{R}\\
  x \mapsto \sum{a_nx^n} \text{, with }R \neq 0
\end{cases}\]

If R = 0, then $\sum{a_nx^n}$ is only convergent at x = 0 $\implies D_f = {0}$ and \\

$f(0) = a_0$ and is divergent otherwise. \\

If $R \in \mathbb{R_+^*}$, then : 

\[\begin{cases}
  (-R, R) \, \cap D_f = (-R, R) \\
  (-\infty, -R) \, \cap D_f = \emptyset\\
   (R, +\infty) \, \cap D_f = \emptyset
\end{cases}\]
\bigskip

\textbf{How to define R :}
\bigskip

D'Alembert's criteria for power series : \\

Let $\sum{a_nx^n}$ a power series, $\exists \, n_0\in \mathbb{N}, (n \ge n_0) \implies a_n \neq 0$. \\

If $\exists \, P \in \mathbb{R_+} \, \cup \{+\infty\}$ such that $|\frac{a_{n + 1}}{a_n}| \to P$, then : 

\[
\begin{cases}
  P = 0 \implies R = +\infty \\
  P \in \mathbb{R_+^*} \implies R = \frac{1}{P} \\
  P = +\infty \implies R = 0
\end{cases}\]
\bigskip

\begin{itemize}
  \item $\forall n \in \mathbb{N}, \sum{a_nx^n} : |\frac{a_{n+1}x^{n+1}}{a_nx^n}| = |\frac{a_{n+1}}{a_n}||x| \underset{n \, \to \, +\infty}{\to} P|x| $\\
\end{itemize}

Then : \\

\begin{itemize}
  \item If $P|x| < 1, \sum{a_nx^n} $ converges, where $|x| < \frac{1}{P}$. Thus $R \ge \frac{1}{P}$\\
  \item If $P|x| > 1, \sum{a_nx^n} $ diverges, where $|x| > \frac{1}{P}$. Thus $R \le \frac{1}{P}$\\
\end{itemize}

\newpage

Hence R = $\frac{1}{P}$ 
\bigskip

\begin{itemize}
  \item If P = 0, then $\forall x \in \mathbb{R^*}, \frac{a_{n+1}}{a_n} |x| \underset{n \, \to \,+\infty}{\to} 0$, thus $\sum{a_nx^n}$ diverges hence R = $+\infty$ \\
  \item If P = $+\infty$, then $\forall x \in \mathbb{R^*}, \frac{a_{n+1}}{a_n} |x| \underset{n \, \to \,+\infty}{\to} +\infty$, thus $\sum{a_nx^n}$ diverges hence R $\le 0$ \\
  \item At x = 0, $\sum{a_nx^n converges \implies R \le 0 \implies R = 0}$
\end{itemize}
\bigskip

Ex : $\sum{x^n}, \forall n \in \mathbb{N}, a_n = 1; \frac{a_{n+1}}{a_n} \underset{n \, \to \, +\infty}{\to} 1 \implies R = 1$ \\

At x = 1 $\implies \sum{1} $ diverges, $D_f$ = $(-1, 1) \implies S $ \\

\[\begin{cases}
  (-1, 1) \to \mathbb{R} \\
  x \mapsto S(x) = \sum{x^k} = \frac{1}{1-x}
\end{cases}
\]\\

At x = -1 $\implies \sum{(-1)^n}$ diverges  \\

\[ \sum{\frac{x^n}{n!}}, \forall n \in \mathbb{N}, a_n = \frac{1}{n!}, \frac{a_{n+1}}{a_n} \implies \frac{n!}{(n+1)!} = \frac{1}{n+1} \underset{n\,\to\,+\infty}{0} \implies R = +\infty
\]\\

\[D_f = (-\infty, +\infty), S : \begin{cases}
  \mathbb{R} \to \mathbb{R} \\
  x \mapsto \sum{\frac{x^n}{n!}} = e^x
\end{cases}\]\\

\[\sum{\frac{x^n}{n!}}, x = 1 \implies \sum{1} \text{ diverges and }x = -1 \implies \]
\bigskip



\bigskip
\subsection*{Definition}

Let $(\Omega, P(\Omega), \mathbb{P})$ be a probability space.  
We call a \textbf{Discrete Infinite Random Variable} a random variable $X$ such that $X(\Omega)$ is indexable by $\mathbb{N}$, i.e., there exists a bijection from $\mathbb{N}$ to $X(\Omega)$. We then denote:

\[
X(\Omega) = \{ x_k \mid k \in \mathbb{N} \}.
\]

Hence, we will only consider the cases when $X(\Omega) \subset \mathbb{N}$, i.e., $X$ takes only integer values.

\subsection*{Distribution of $X$}

We define the distribution of $X$ with $P(X = k)$, $k \in X(\Omega)$ where $X(\Omega) \subset \mathbb{N}$. Then:

\[
\sum_{k=0}^{+\infty} P(X = k) = P(\Omega) = 1.
\]

Note that if $k = 0$, $X(\Omega) = \mathbb{N}$.

\subsection*{Geometric Distribution}

\begin{tikzpicture}[
  grow=right,
  level distance=35mm,
  sibling distance=25mm,
  edge from parent/.style={draw, -latex},
  every node/.style={font=\footnotesize},
  sloped
]
\node {Coin 1}
  child { node {H}
    child { node {HH} edge from parent node[above] {$\frac{1}{2}$} }
    child { node {HT} edge from parent node[below] {$\frac{1}{2}$} }
    edge from parent node[above] {$\frac{1}{2}$}
  }
  child { node {T}
    child { node {TH} edge from parent node[above] {$\frac{1}{2}$} }
    child { node {TT} edge from parent node[below] {$\frac{1}{2}$} }
    edge from parent node[below] {$\frac{1}{2}$}
  };
\end{tikzpicture}

\begin{tikzpicture}
  \fill[fill=yellow] (0,0) -- (1,0) -- (0.5,0.866) -- cycle;
  \node at (0.5,0.4) {\textbf{!}};
\end{tikzpicture}


Infinite number of trials.  \\ 

$X$ : the rank of first success, or the number of trials until the first success.

\begin{itemize}
  \item $X(\Omega) = \{1,2,3,\dots\} = \mathbb{N}^*$
  \item $\forall k \in \mathbb{N}^*, \quad P(X = k) = q^{k - 1} \cdot p \quad \Leftrightarrow \quad X \sim \text{Geom}(p)$
\end{itemize}

Consider the series with general term $P(X = k) = q^{k-1} p$:
\[
\sum_{k \in X(\Omega)} q^{k-1} p = (1-q) \sum_{k \ge 1} q^{k-1}.
\]

This geometric series converges for $q \in (0,1)$:
\[
\sum_{k=1}^{+\infty} q^{k-1} = \sum_{k=0}^{+\infty} q^k = \frac{1}{1-q} \quad \implies \quad (1-q) \sum_{k=1}^{+\infty} q^{k-1} = 1.
\]

\subsection*{Expectation and Variance}

Let $X$ be a discrete infinite random variable with $X(\Omega) = \mathbb{N}$. Then:

\begin{itemize}
  \item The expected value of $X$ is
  \[
    \mathbb{E}(X) = \sum_{k \in X(\Omega)} k \, P(X = k),
  \]
  provided the series converges.
  \item The variance of $X$ is
  \[
    \mathbb{V}(X) = \sum_{k \in X(\Omega)} (k - \mathbb{E}(X))^2 P(X = k),
  \]
  provided $\mathbb{E}(X)$ exists and $\sum k^2 P(X=k)$ converges.
\end{itemize}

\textbf{Remark:} Under the existence conditions, we have
\[
\mathbb{V}(X) = \mathbb{E}(X^2) - (\mathbb{E}(X))^2.
\]

\subsection*{Properties of $\mathbb{E}$ and $\mathbb{V}$}

\text{Let X and Y two Infinite Discrete Random Value with $\mathbb{E}$ and $\mathbb{V}$ and $(a,b) \in \mathbb{R}^2$}

\text{Then :}

\[
\mathbb{E}(X + Y) = \mathbb{E}(X) + \mathbb{E}(Y) \\
\mathbb{E}(aX + bY) = a\mathbb{E}(X) + b\mathbb{E}(Y) \\
\mathbb{E}(aX + b) = a\mathbb{E}(X) + b \\
\mathbb{V}(aX) = a^2\mathbb{V}(X)\\
\]

\subsection*{Generating function of Infinite Discrete Random Variable :}

\text{Let X and Y two Infinite Discrete Random Variable such that :} \\

\text{ $X(\Omega) = \mathbb{N}$, then :}
\text{The generating function of X is $G_X : t \mapsto \mathbb{E}(t^x)$, i.e the sum of the series :}
\[ \sum{P(X = k) \times t^k} \\
\implies G_X : t \mapsto \sum_{\, k \, = \, 0}^{+\infty}{P(X = k) \times t^k}
\]

\text{Here, P(X = k) could be named $a_n$ which is a sequence.}\\

\text{We also talk about "the generating series of X"}
\[ t = 1 \implies \sum_{\, k \, = \, 0}^{+\infty}{P(X = k) \times t^k} \text{converges and} G_X(1) = 1 \implies R \geq 1
\]
\subsection*{Properties of $G_X$}
\begin{tikzpicture}
  \fill[fill=yellow] (0,0) -- (1,0) -- (0.5,0.866) -- cycle;
  \node at (0.5,0.4) {\textbf{!}};
\end{tikzpicture}

\text{(-1, 1) and -1, 1 excluded :}
\[
\begin{cases}
G_X \in C([-1,1]) \\
G_X(1) = 1
\end{cases}
\]

\text{If Y another I.D.R.V, $Y(\Omega) = \mathbb{N}$, $G_{X+Y} = G_X + G_Y$ over $[-1, 1]$ where -1 and 1 are excluded}
\text{And :}

\[
\begin{cases}
\mathbb{E}(X) = G_X'(1) \\
\mathbb{V}(X) = G_X''(1) + G_X'(1) - (G_X'(1))^2
\end{cases}
\]

\[
\sum{P(X = k \times (-1)^k)}
\]

\[
\Leftrightarrow \sum{k \times (q)^{k-1}\times p}
\]

\[
\Leftrightarrow p \sum_{k \geq 1}{k \times (q)^{k-1}\times p} is convergent on ]-1, 1[ and \mathbb{E}(X) = p \times (\frac{1}{1-q})
\]
\[
\frac{p}{(1 - q)^2} = \frac{1}{1 - q} = \frac{1}{p}
\]
\end{document}
